{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10189065-108c-445d-978d-9e31aaa1be52",
   "metadata": {},
   "source": [
    "# Load and run model predictions 加载和运行模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc5866-e1d2-4c87-9b24-9e40dc5ff5b4",
   "metadata": {},
   "source": [
    "# Load the model 加载模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4259c1af-ab08-4f87-b154-c6dd62f2768c",
   "metadata": {},
   "source": [
    "在本单元中，我们将了解如何加载模型及其持久参数状态和推理模型预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2f4252-4a6a-4076-baac-8b74bbebfdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import onnxruntime\n",
    "from torch import nn\n",
    "import torch.onnx as onnx\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4bf0f2-85de-4965-be0d-732003a6f869",
   "metadata": {},
   "source": [
    "为了加载模型，我们将定义模型类，其中包含用于训练模型的神经网络的状态和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5323d5f9-e5b6-460d-8e37-25812e5d6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b468ad15-fd22-4e78-a8d2-3367c8a41e3b",
   "metadata": {},
   "source": [
    "加载模型权重时，我们需要首先实例化模型类，因为该类定义了网络的结构。接下来，我们使用 `load_state_dict()` 方法加载参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a398fd-92d0-48ae-b798-1d5dee40671c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load('data/model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d75e166-cd0f-4e7b-9ebd-6ab66c3d18a5",
   "metadata": {},
   "source": [
    "> **注意：**请务必在推理之前调用 `model.eval()` 方法，以将 dropout 和批量归一化层设置为评估模式。否则，您将看到不一致的推理结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e777dab-36b1-46d9-a82d-7994e17fa718",
   "metadata": {},
   "source": [
    "## Model Inference 模型推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cdfbdb-9074-432b-b357-0c978beaa382",
   "metadata": {},
   "source": [
    "优化模型以在各种平台和编程语言上运行是很困难的。在所有不同的框架和硬件组合中最大限度地提高性能非常耗时。**Open Neural Network Exchange (ONNX)** 开放神经网络交换运行时为您提供了一种解决方案，可在任何硬件、云或边缘设备上进行一次训练并加速推理。 \n",
    "\n",
    "ONNX 是许多供应商支持的通用格式，用于共享神经网络和其他机器学习模型。您可以使用 ONNX 格式在其他编程语言(Java, JavaScript, C# 和 ML.NET)和框架上对模型进行推理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58b5e2b-b834-4639-97b3-17b679385f81",
   "metadata": {},
   "source": [
    "## Exporting the model to ONNX 将模型导出到 ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e16339-1845-4c5e-b9e0-c1269c1ae98e",
   "metadata": {},
   "source": [
    "PyTorch 还具有本机 ONNX 导出支持。然而，考虑到 PyTorch 执行图的动态特性，导出过程必须遍历执行图以生成持久的 ONNX 模型。因此，应将适当大小的测试变量传递到导出例程中（在我们的例子中，我们将创建正确大小的虚拟零张量。您可以从训练数据集的`shape`函数中获取大小：`tensor.shape`）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c537e4ae-c51f-4a6f-a7b5-cb18b999a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.zeros((1,28,28))\n",
    "onnx_model = 'data/model.onnx'\n",
    "onnx.export(model, input_image, onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347f7ca-6f53-468c-9bf2-e7fdd4ac88f1",
   "metadata": {},
   "source": [
    "我们将使用测试数据集作为示例数据，从 ONNX 模型进行推理以进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90cf4c2a-bd25-4fc6-bdca-ca17d130b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "x, y = test_data[0][0], test_data[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cdceb5-b1a2-4cef-a8f5-8d97074b83cc",
   "metadata": {},
   "source": [
    "我们使用 `onnxruntime.InferenceSession` 创建推理会话。要推断 ONNX 模型，请调用 `run` 并传入您想要返回的输出列表（如果您需要所有输出，请保留为空）和输入值的映射。结果是输出列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd1112c3-6b91-4d93-89be-12bc54b59747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "session = onnxruntime.InferenceSession(onnx_model, None)\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "result = session.run([output_name], {input_name:x.numpy()})\n",
    "predicted, actual = classes[result[0][0].argmax(0)], classes[y]\n",
    "print(f'Predicted: \"{predicted}\", Actual: {actual}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f245ea-6ebd-4816-a801-4e6dbcbd1d54",
   "metadata": {},
   "source": [
    "ONNX 模型使您能够在不同平台上以不同编程语言运行推理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8436a3c3-2e16-4bf7-bf17-399e9b3da6e2",
   "metadata": {},
   "source": [
    "# 知识检查"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3843e93-15ce-4f42-bef1-4a88059c7474",
   "metadata": {},
   "source": [
    "什么是 PyTorch 模型 state_dict？ \n",
    "\n",
    "它是模型的内部状态字典，用于存储已学习的参数。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
